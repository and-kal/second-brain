---
title: "Notes on Effective Altruism"
date: "2025-01-02"
draft: true
---

What is the argument for our current generation having a stronger moral obligation towards all future generations than towards the next few generations?

Another thing that still seems highly doubtful is that the things an A(G)I will produce are necessarily better than products of human labour and thought. After all A(G)Is seem to be modelled after human ideas and reasoning and therefore might always only be an insufficient copy of themselves.

Furthermore, I think of the threshold towards Singularity as the moment when AIs are capable of creating AGIs themselves. Now, as examples of model collapse in AI reasearch proof, for an AI to advance and become better, not worse, human intervention, moderation and data selection is necessary, so that there can be no self-contained AI network independent from human intervention. Hence, keeping A(G)Is running will require a vast amount of human labour and other resources.

Is there some kind of computable objective morality that an AGI will benevolently steer towards; and will AGi be allowed to move humanity towards this ideal state without any external forces of power (governments, companies, etc.) stopping it from, e.g., raising estate tax, introducing wealth tax, redistribution of wealth, or even Socialism, if it holds indeed the most utilitarian model of organizing a society as I like to believe?
